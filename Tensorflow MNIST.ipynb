{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=False) \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnist.train.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_img = mnist.train.images[1].reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(single_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(single_img, cmap= 'gist_gray') # to see image in grey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameter\n",
    "learning_rate = 0.001\n",
    "num_steps= 2000\n",
    "batch_size= 120\n",
    "\n",
    "# network paramter\n",
    "num_input = 28*28  # MNIST data input(img shape : 28 * 28)\n",
    "num_classes= 10  # MNIST total classes 0 -9 digits\n",
    "dropout= 0.25  # dropout , probability to drop  a unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a neural network\n",
    "def conv_net(x_dict, n_classes,dropout, reuse, is_training):\n",
    "    \n",
    "    # defining scope of reuse the variable\n",
    "    with tf.variable_scope('convNet', reuse= reuse):\n",
    "        # TF Estimator input is a dict, in case of multiple inputs\n",
    "        x= x_dict['images']\n",
    "        \n",
    "        # mnist data is 1D input that is 784 (28 * 28 pixels)\n",
    "        # Reshape the match picture format(Height * Width * channel)\n",
    "        # Tensor input become 4D: [Batch size, Height, Width, channel]\n",
    "        x= tf.reshape(x, [-1,28,28,1])\n",
    "        \n",
    "        # convolution layer with 32 filter and  kernal size of 5 \n",
    "        conv1 = tf.layers.conv2d(x ,32, 5, activation = tf.nn.relu)\n",
    "        # maxpooling (down -sampling) with  strides of 2  and kernel size of 2\n",
    "        conv1 = tf.layers.max_pooling2d(conv1, 2,2)\n",
    "        \n",
    "        # convolution layer with size of 64 and kernel size of 3\n",
    "        conv2= tf.layers.conv2d(conv1, 64, 3, activation= tf.nn.relu)\n",
    "        # maxpooling ( down sampling ) with strides of 2 and kernel size of 2\n",
    "        conv2 = tf.layers.max_pooling2d(conv2, 2,2)\n",
    "        \n",
    "        # flatten the into 1d for fully connected layer\n",
    "        fc1 = tf.contrib.layers.flatten(conv2)\n",
    "        \n",
    "        # fully connected layers\n",
    "        fc1= tf.layers.dense(fc1,1024)\n",
    "        \n",
    "        # apply dropout\n",
    "        fc1 = tf.layers.dropout(fc1,rate=dropout, training= is_training)\n",
    "        \n",
    "        # output layers prediction \n",
    "        out = tf.layers.dense(fc1, n_classes)\n",
    "        \n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model fuction\n",
    "def model_fun( features, labels, mode):\n",
    "    # build the neural network\n",
    "    # Dropout have 2 different behavior  at training and prediction time , \n",
    "    # we need to create 2 distinct computation graph with same weights\n",
    "    \n",
    "    logit_train = conv_net(features, num_classes, dropout, reuse=False, is_training=True)\n",
    "    logit_test = conv_net(features, num_classes, dropout, reuse=True, is_training=False)\n",
    "    \n",
    "    # prediction\n",
    "    pred_classes = tf.argmax(logit_test, axis=1)\n",
    "    pred_proba= tf.nn.softmax(logit_test)\n",
    "    \n",
    "    # if prediction mode\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes) \n",
    "    \n",
    "    # define loss and optimizer\n",
    "    loss_op = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "            logits= logit_train, \n",
    "            labels= tf.cast(labels, dtype= tf.int32)))\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate= learning_rate)\n",
    "    train_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())\n",
    "    \n",
    "    # evaluate accuracy of model\n",
    "    acc_op= tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "    \n",
    "    estim_spacs = tf.estimator.EstimatorSpec( mode = mode,\n",
    "                                            predictions=pred_classes,\n",
    "                                            loss= loss_op,\n",
    "                                            train_op= train_op,\n",
    "                                            eval_metric_ops= {'accuracy':acc_op})\n",
    "    return estim_spacs\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Estimator\n",
    "model = tf.estimator.Estimator(model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input function for training\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "            x= {'images':mnist.train.images}, y =mnist.train.labels,\n",
    "            batch_size=batch_size, num_epochs=None, shuffle= True)\n",
    "\n",
    "model.train(input_fn, steps=num_steps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict single images\n",
    "n_images = 10\n",
    "# Get images from test set\n",
    "test_images = mnist.test.images[:n_images]\n",
    "# Prepare the input data\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'images': test_images}, shuffle=False)\n",
    "# Use the model to predict the images class\n",
    "preds = list(model.predict(input_fn))\n",
    "\n",
    "# Display\n",
    "for i in range(n_images):\n",
    "    plt.imshow(np.reshape(test_images[i], [28, 28]), cmap='gray')\n",
    "    plt.show()\n",
    "    print(\"Model prediction:\", preds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
